{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'osc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ZHENGZ~1\\AppData\\Local\\Temp/ipykernel_15388/3180290000.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mosc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'osc'"
     ]
    }
   ],
   "source": [
    "# ==== Part 0: import libs\n",
    "import argparse  # argparse is used to conveniently set our configurations\n",
    "import cv2\n",
    "import json\n",
    "import osc\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# ==== Part 1: data loader\n",
    "\n",
    "# construct a dataset and a data loader, more details can be found in\n",
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html?highlight=dataloader\n",
    "class ListDataset(Dataset):\n",
    "    def __init__(self, im_dir, file_path, norm_size=(32, 32)):\n",
    "        \"\"\"\n",
    "        :param im_dir: path to directory with images\n",
    "        :param file_path: json file containing image names and labels\n",
    "        :param norm_size: image normalization size, (width, height)\n",
    "        \"\"\"\n",
    "\n",
    "        # this time we will try to recognize 26 English letters (case-insensitive)\n",
    "        letters = string.ascii_letters[-26:]  # ABCD...XYZ\n",
    "        self.alphabet = {letters[i]: i for i in range(len(letters))}\n",
    "\n",
    "        # get image paths and labels from json file\n",
    "        with open(file_path, 'r') as f:\n",
    "            imgs = json.load(f)\n",
    "            im_names = list(imgs.keys())\n",
    "\n",
    "            self.im_paths = [os.path.join(im_dir, im_name) for im_name in im_names]\n",
    "            self.labels = list(imgs.values())\n",
    "\n",
    "        self.norm_size = norm_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert index <= len(self), 'index range error'\n",
    "\n",
    "        # read an image and convert it to grey scale\n",
    "        im_path = self.im_paths[index]\n",
    "        im = cv2.imread(im_path)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # image pre-processing, after pre-processing, the values of image pixels are converted to [0,1]\n",
    "        im = cv2.resize(im, self.norm_size)\n",
    "        # convert numpy image to pytorch tensor, and normalize values to [-1, 1]\n",
    "        im = (torch.from_numpy(im).float() - 127.5) / 127.5\n",
    "        # add the first channel dimension\n",
    "        im = im.unsqueeze(0)\n",
    "\n",
    "        # get the label of the current image\n",
    "        # upper() is used to convert a letter into uppercase\n",
    "        label = self.labels[index].upper()\n",
    "\n",
    "        # convert an English letter into a number index\n",
    "        label = self.alphabet[label]\n",
    "\n",
    "        return im, label\n",
    "\n",
    "\n",
    "def dataLoader(im_dir, file_path, norm_size, batch_size, workers=0):\n",
    "    \"\"\"\n",
    "    :param im_dir: path to directory with images\n",
    "    :param file_path: file with image paths and labels\n",
    "    :param norm_size: image normalization size, (height, width)\n",
    "    :param batch_size: batch size\n",
    "    :param workers: number of workers for loading data in multiple threads\n",
    "    :return: a data loader\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = ListDataset(im_dir, file_path, norm_size)\n",
    "    return DataLoader(dataset,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True if 'train' in file_path else False,  # shuffle images only when training\n",
    "                      num_workers=workers)\n",
    "\n",
    "\n",
    "# ==== Part 2: construct a model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.pool3 = nn.AdaptiveAvgPool2d(1)\n",
    "        self.layer4 = nn.Linear(in_features=32, out_features=26)  # 26 letters\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        # x: input image with shape [b, 1, h, w]\n",
    "        f1 = self.layer1(x)  # [b, 8, h, w]\n",
    "        p1 = self.pool1(f1)  # [b, 8, h//2, w//2]\n",
    "        f2 = self.layer2(p1)  # [b, 16, h//2, w//2]\n",
    "        p2 = self.pool2(f2)  # [b, 16, h//4, w//4]\n",
    "        f3 = self.layer3(p2)  # [b, 32, h//4, w//4]\n",
    "        p3 = self.pool3(f3)  # [b, 32, 1, 1]\n",
    "        out = self.layer4(p3.view(-1, 32))  # [b, 26]\n",
    "\n",
    "        if return_features:\n",
    "            return out, f1, f2, f3\n",
    "        return out\n",
    "\n",
    "\n",
    "# ==== Part 3: training and validation\n",
    "def train_val(im_dir, train_file_path, val_file_path,\n",
    "              norm_size, n_epochs, batch_size,\n",
    "              lr, valInterval, device='cpu'):\n",
    "    \"\"\"\n",
    "    The main training procedure\n",
    "    ----------------------------\n",
    "    :param im_dir: path to directory with images\n",
    "    :param train_file_path: file list of training image paths and labels\n",
    "    :param val_file_path: file list of validation image paths and labels\n",
    "    :param norm_size: image normalization size, (height, width)\n",
    "    :param n_epochs: number of training epochs\n",
    "    :param batch_size: batch size of training and validation\n",
    "    :param lr: learning rate\n",
    "    :param valInterval: the frequency of validation, e.g., if valInterval = 5, then do validation after each 5 training epochs\n",
    "    :param device: 'cpu' or 'cuda', we can use 'cpu' for our homework if GPU with cuda support is not available\n",
    "    \"\"\"\n",
    "\n",
    "    # training and validation data loader\n",
    "    trainloader = dataLoader(im_dir, train_file_path, norm_size, batch_size)\n",
    "    valloader = dataLoader(im_dir, val_file_path, norm_size, batch_size)\n",
    "\n",
    "    # initialize a model\n",
    "    model = SimpleCNN()\n",
    "    # put the model on CPU or GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # loss function and optimizer\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "    # training\n",
    "    for epoch in range(n_epochs):\n",
    "        # set the model in training mode\n",
    "        model.train()\n",
    "\n",
    "        # to save total loss in one epoch\n",
    "        total_loss = 0.\n",
    "        for step, (ims, labels) in enumerate(trainloader):  # get a batch of data\n",
    "\n",
    "            # set data type and device\n",
    "            ims, labels = ims.to(device), labels.to(device)\n",
    "\n",
    "            # clear gradients in the optimizer\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # run the forward process\n",
    "            out = model(ims)\n",
    "\n",
    "            # compute the cross entropy loss, and call backward propagation function\n",
    "            loss = ce_loss(out, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # sum up of total loss, loss.item() return the value of the tensor as a standard python number\n",
    "            # this operation is not differentiable\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # call a function to update the parameters of the models\n",
    "            optimizer.step()\n",
    "\n",
    "        # average of the total loss for iterations\n",
    "        avg_loss = total_loss / len(trainloader)\n",
    "        print('Epoch {:02d}: loss = {:.3f}'.format(epoch + 1, avg_loss))\n",
    "\n",
    "        # validation\n",
    "        if (epoch + 1) % valInterval == 0:\n",
    "\n",
    "            # set the model in evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            n_correct = 0.  # number of images that are correctly classified\n",
    "            n_ims = 0.  # number of total images\n",
    "\n",
    "            with torch.no_grad():  # we do not need to compute gradients during validation\n",
    "\n",
    "                for ims, labels in valloader:\n",
    "                    ims, labels = ims.to(device), labels.to(device)\n",
    "                    out = model(ims)\n",
    "                    predictions = out.argmax(1)\n",
    "\n",
    "                    # sum up the number of images correctly recognized\n",
    "                    n_correct += torch.sum(predictions == labels)\n",
    "                    # sum up the total image number\n",
    "                    n_ims += ims.size(0)\n",
    "\n",
    "            # show prediction accuracy\n",
    "            print('Epoch {:02d}: validation accuracy = {:.1f}%'.format(epoch + 1, 100 * n_correct / n_ims))\n",
    "\n",
    "    # save model parameters in a file\n",
    "    if not os.path.exists('saved_models'):\n",
    "        os.makedirs('saved_models')\n",
    "    model_save_path = 'saved_models/recognition.pth'\n",
    "    torch.save({'state_dict': model.state_dict()}, model_save_path)\n",
    "    print('[Info] Model saved in {}\\n'.format(model_save_path))\n",
    "\n",
    "\n",
    "# ==== Part 4: test\n",
    "def test(model_path, im_dir='data/images',\n",
    "         test_file_path='data/test.json',\n",
    "         norm_size=(32, 32), batch_size=8,\n",
    "         device='cpu'):\n",
    "    \"\"\"\n",
    "    Test procedure\n",
    "    ---------------\n",
    "    :param model_path: path of the saved model\n",
    "    :param im_dir: path to directory with images\n",
    "    :param test_file_path: file with test image paths and labels\n",
    "    :param norm_size: image normalization size, (height, width)\n",
    "    :param batch_size: test batch size\n",
    "    :param device: 'cpu' or 'cuda'\n",
    "    \"\"\"\n",
    "\n",
    "    # load configurations from saved model\n",
    "    checkpoint = torch.load(model_path)\n",
    "\n",
    "    # initialize the model\n",
    "    model = SimpleCNN()\n",
    "    # load model parameters we saved in model_path\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model = model.to(device)\n",
    "    print('[Info] Load model from {}'.format(model_path))\n",
    "\n",
    "    # enter the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # test loader\n",
    "    testloader = dataLoader(im_dir, test_file_path, norm_size, batch_size)\n",
    "\n",
    "    # run the test process\n",
    "    n_correct = 0.\n",
    "    n_ims = 0.\n",
    "\n",
    "    with torch.no_grad():  # we do not need to compute gradients during test stages\n",
    "        for ims, labels in testloader:\n",
    "            ims, labels = ims.to(device), labels.to(device)\n",
    "            out = model(ims)\n",
    "            predictions = out.argmax(1)\n",
    "            n_correct += torch.sum(predictions == labels)\n",
    "            n_ims += ims.size(0)\n",
    "\n",
    "    print('[Info] Test accuracy = {:.1f}%'.format(100 * n_correct / n_ims))\n",
    "\n",
    "\n",
    "def predict(model_path, im_path, norm_size=(32, 32), device='cpu'):\n",
    "    # read image and preprocess\n",
    "    assert os.path.exists(im_path), '{} not exists!'.format(im_path)\n",
    "    im = cv2.imread(im_path)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    im = cv2.resize(im, norm_size)\n",
    "    im = (torch.from_numpy(im).float() - 127.5) / 127.5\n",
    "    im = im.view(1, 1, norm_size[1], norm_size[0])\n",
    "\n",
    "    # load configurations from saved model\n",
    "    checkpoint = torch.load(model_path)\n",
    "\n",
    "    # initialize the model\n",
    "    model = SimpleCNN()\n",
    "    # load model parameters we saved in model_path\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model = model.to(device)\n",
    "    print('[Info] Load model from {}'.format(model_path))\n",
    "\n",
    "    # run the forward process\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(im)\n",
    "    prediction = out[0].argmax().item()\n",
    "    prediction = chr(prediction + ord('A'))\n",
    "\n",
    "    print('{}: {}'.format(os.path.basename(im_path), prediction))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # set random seed for reproducibility\n",
    "    seed = 2022\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # set configurations\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--mode', type=str, default='train', help='train or test')\n",
    "    parser.add_argument('--im_dir', type=str, default='data/images',\n",
    "                        help='path to directory with images')\n",
    "    parser.add_argument('--train_file_path', type=str, default='data/train.json',\n",
    "                        help='file list of training image paths and labels')\n",
    "    parser.add_argument('--val_file_path', type=str, default='data/validation.json',\n",
    "                        help='file list of validation image paths and labels')\n",
    "    parser.add_argument('--test_file_path', type=str, default='data/test.json',\n",
    "                        help='file list of test image paths and labels')\n",
    "    parser.add_argument('--batchsize', type=int, default=8, help='batch size')\n",
    "    parser.add_argument('--device', type=str, default='cpu', help='cpu or cuda')\n",
    "\n",
    "    # configurations for training and test\n",
    "    parser.add_argument('--norm_size', type=str, default='32,32',\n",
    "                        help='image normalization size, height,width, splitted by comma')\n",
    "    parser.add_argument('--epoch', type=int, default=30, help='number of training epochs')\n",
    "    parser.add_argument('--valInterval', type=int, default=10, help='the frequency of validation')\n",
    "    parser.add_argument('--lr', type=float, default=0.01, help='learning rate')\n",
    "    parser.add_argument('--model_path', type=str, default='saved_models/recognition.pth',\n",
    "                        help='path of a saved model')\n",
    "\n",
    "    # configurations for prediction\n",
    "    parser.add_argument('--im_path', type=str, default='', help='path of an image to be recognized')\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "\n",
    "    # -- run the code for training and validation\n",
    "    if opt.mode == 'train':\n",
    "        train_val(im_dir=opt.im_dir,\n",
    "                  train_file_path=opt.train_file_path,\n",
    "                  val_file_path=opt.val_file_path,\n",
    "                  norm_size=(int(opt.norm_size.split(',')[0]), int(opt.norm_size.split(',')[1])),\n",
    "                  n_epochs=opt.epoch,\n",
    "                  batch_size=opt.batchsize,\n",
    "                  lr=opt.lr,\n",
    "                  valInterval=opt.valInterval,\n",
    "                  device=opt.device)\n",
    "\n",
    "    # -- test the saved model\n",
    "    elif opt.mode == 'test':\n",
    "        test(model_path=opt.model_path,\n",
    "             im_dir=opt.im_dir,\n",
    "             test_file_path=opt.test_file_path,\n",
    "             norm_size=(int(opt.norm_size.split(',')[0]), int(opt.norm_size.split(',')[1])),\n",
    "             batch_size=opt.batchsize,\n",
    "             device=opt.device)\n",
    "\n",
    "    elif opt.mode == 'predict':\n",
    "        predict(model_path=opt.model_path,\n",
    "                im_path=opt.im_path,\n",
    "                norm_size=(int(opt.norm_size.split(',')[0]), int(opt.norm_size.split(',')[1])),\n",
    "                device=opt.device)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError('mode should be train or test')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d361cc1f4b0c2e32a611319f5f50aa2240a47aaad24a494d696fb69a0ef082a7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mrenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
